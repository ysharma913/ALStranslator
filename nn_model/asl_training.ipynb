{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.resources import path\n",
    "\n",
    "from torch import FloatTensor, LongTensor\n",
    "from torchvision import transforms\n",
    "\n",
    "class MNISTDatasetASL(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.X, self.Y = self.get_data_mapping(path)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomResizedCrop(28, scale=(0.8, 1.2)),\n",
    "            transforms.RandomHorizontalFlip(p = 0.5),\n",
    "            transforms.RandomInvert(p=0.25),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)]\n",
    "        )\n",
    "\n",
    "    def get_data_mapping(self, path):\n",
    "        dataset = pd.read_csv(path)\n",
    "        Y = torch.tensor(dataset['label'].values.astype(np.int8))\n",
    "        X = torch.tensor(dataset.drop('label', axis = 1).values.astype(np.int8)) \n",
    "        return (X, Y)    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.Y[idx].type(LongTensor)\n",
    "        input = self.transform(self.X[idx].reshape(1, 28, 28).type(FloatTensor))\n",
    "        return (input, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "train_path = \"data/sign_mnist_train.csv\"\n",
    "test_path = \"data/sign_mnist_test.csv\"\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(MNISTDatasetASL(train_path), batch_size=64, shuffle = True)\n",
    "testLoader = torch.utils.data.DataLoader(MNISTDatasetASL(train_path), batch_size=64, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACSUlEQVR4nCXSzW4bZRQG4Pd8c74Zz0/GtdOoBSkREqooEuIm4BK4G66HDXs2wBYQGyoqtVKJIFAohBqTOontjGfO+7LguYbHPh3GGElFSJRZRCrMYGYpeZAhcZJIcMrLcrNNZmYmuiSShEI6HJSia/8cwszMzEMSGSK50SzK5tof5heRkABnTFRQxO7u+KR4a77q6tcHYwLgIEmJgb1V7zavL25arSMZYHAFGcEIHnww/+PSEmSSBDiloBgaw6cN95hxMNBAmQcpkhRzwcv1Pp/0L9clZIB5UBJjOqDxeCl0x+/xryyYmRyAFHa96/tqyLPc9t0xQ5YKmgskxdvJ2ro85GZeoksBCCYXydA4RRSL7aurcuOn8zwVoBJckojDmFIu+syYytkwjUkJkRwShB3j7mqL+dtzmx8tP/pu1SCBHiEi9uMsTyltV9Oiq/F4+fxJZiGXGLYbChvT0b3drq9b3/LRh5ufGppDAm8mU392f8F/R7W5XCybD54LSIJsfztYt3zwzqP3q39YJqvLm0sT5ZL0Zief15rVq+v6XjXepb+/eeqTwUEb34x116RIiIfNA5uGyx+e3BYCHbDNNs2aXJTenC5SvhtefH8+FhLgglZjW1V5VnkuuZ/GZ1//5knGZA5fX1V1M+u6Lg/DreXzLy8q0GCSB35X1x/1fd8WEZ5+/urXUjABoFfX67Y96ruuLYtU4dkXv1QBK0yQpU/mUddtW9fZy3r69vOLSsD/HWH6+Px4eTafn9w/Pfvxs6fhEACzQsn+A0NuhZyqfAJGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE4EE0DB6A0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage()])\n",
    "for img, y in testLoader:\n",
    "    img = transform(img[0].reshape(1,28,28))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network Architectyre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ASLClassifier(nn.Module):\n",
    "    class ConvBlock(nn.Module):\n",
    "        def __init__(self, input_c, output_c, kernel_size):\n",
    "            super().__init__()\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Conv2d(input_c, output_c, kernel_size),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2,2)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.block(x)\n",
    "\n",
    "        \n",
    "    def __init__(self):\n",
    "        print(\"HERE\")\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            self.ConvBlock(1, 6, 3),\n",
    "            self.ConvBlock(6, 16, 3)\n",
    "        )\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 25)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        flat_out = self.conv(x).flatten(start_dim = 1)\n",
    "        return self.mlp(flat_out)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return torch.argmax(self.forward(x), dim=1)\n",
    "\n",
    "net = ASLClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 33653), started 12:32:55 ago. (Use '!kill 33653' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d534f9c375f5227a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d534f9c375f5227a\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n",
      "LOSS AT EPOCH 0 : 2471.107666015625\n",
      "Valid Accuracy AT EPOCH 0 : 0.2797304689884186\n",
      "LOSS AT EPOCH 1 : 1568.4107666015625\n",
      "Valid Accuracy AT EPOCH 1 : 0.5014023184776306\n",
      "LOSS AT EPOCH 2 : 1128.689453125\n",
      "Valid Accuracy AT EPOCH 2 : 0.6232016086578369\n",
      "LOSS AT EPOCH 3 : 897.0569458007812\n",
      "Valid Accuracy AT EPOCH 3 : 0.6832271218299866\n",
      "LOSS AT EPOCH 4 : 769.937744140625\n",
      "Valid Accuracy AT EPOCH 4 : 0.7376798391342163\n",
      "LOSS AT EPOCH 5 : 652.2020263671875\n",
      "Valid Accuracy AT EPOCH 5 : 0.7583682537078857\n",
      "LOSS AT EPOCH 6 : 587.7547607421875\n",
      "Valid Accuracy AT EPOCH 6 : 0.7826260924339294\n",
      "LOSS AT EPOCH 7 : 533.3922119140625\n",
      "Valid Accuracy AT EPOCH 7 : 0.807721734046936\n",
      "LOSS AT EPOCH 8 : 475.6503601074219\n",
      "Valid Accuracy AT EPOCH 8 : 0.8246585130691528\n",
      "LOSS AT EPOCH 9 : 446.1098937988281\n",
      "Valid Accuracy AT EPOCH 9 : 0.8271717429161072\n",
      "LOSS AT EPOCH 10 : 414.5137634277344\n",
      "Valid Accuracy AT EPOCH 10 : 0.8504461646080017\n",
      "LOSS AT EPOCH 11 : 396.98095703125\n",
      "Valid Accuracy AT EPOCH 11 : 0.8621016144752502\n",
      "LOSS AT EPOCH 12 : 375.3269958496094\n",
      "Valid Accuracy AT EPOCH 12 : 0.8563467264175415\n",
      "LOSS AT EPOCH 13 : 345.2843017578125\n",
      "Valid Accuracy AT EPOCH 13 : 0.8791477084159851\n",
      "LOSS AT EPOCH 14 : 325.5153503417969\n",
      "Valid Accuracy AT EPOCH 14 : 0.8862501978874207\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.tensorboard as tb\n",
    "from os import path\n",
    "\n",
    "def train(model, train_loader, test_loader, lr = 0.001, epochs = 2, log_dir = 'docs'):\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    global_step = 0\n",
    "\n",
    "    train_logger = tb.SummaryWriter(path.join(log_dir, 'train'))\n",
    "    valid_logger = tb.SummaryWriter(path.join(log_dir, 'valid'))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for X, Y in train_loader:\n",
    "            X = X.type(torch.FloatTensor)\n",
    "            output = model(X)\n",
    "            loss = loss_fn(output, Y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_logger.add_scalar('loss', loss, global_step=global_step)\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "            total_loss += loss\n",
    "        \n",
    "        print(f\"LOSS AT EPOCH {epoch} : {total_loss}\")\n",
    "\n",
    "        # total_correct = 0\n",
    "        # count = 0\n",
    "        # for X, Y in test_loader:\n",
    "        #     predictions = model.predict(X)\n",
    "\n",
    "        #     total_correct += (predictions == Y).sum()\n",
    "        #     count += len(Y)\n",
    "        # print(f\"Valid Accuracy AT EPOCH {epoch} : {total_correct/ count}\")\n",
    "        # valid_logger.add_scalar('accuracy', total_correct/count, global_step=global_step)\n",
    "\n",
    "net = ASLClassifier()\n",
    "train(net, trainLoader, testLoader, lr = 0.001, epochs=15)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Code To Onnpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n",
      "Torch Model Accuracy (baseline):  tensor([0.8088])\n",
      "Torch Model Accuracy (baseline):  0.8064696040156163\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "testLoader = torch.utils.data.DataLoader(MNISTDatasetASL(test_path), batch_size=1)\n",
    "\n",
    "net = ASLClassifier()\n",
    "model = torch.load(\"checkpoint.pth\")\n",
    "net.load_state_dict(model)\n",
    "\n",
    "acc_count = 0\n",
    "count = 0\n",
    "for X, Y in testLoader:\n",
    "    predictions = net.predict(X)\n",
    "    # print(type(predictions == Y))\n",
    "    acc_count += (predictions == Y).type(torch.LongTensor)\n",
    "    count += 1\n",
    "\n",
    "print(f'Torch Model Accuracy (baseline):  {acc_count / count}')\n",
    "\n",
    "\n",
    "# export to onnx\n",
    "fname = \"asl_model.onnx\"\n",
    "dummy = torch.randn(1, 1, 28, 28)\n",
    "net(dummy)\n",
    "torch.onnx.export(net, dummy, fname, input_names=['input'])\n",
    "\n",
    "# check exported model\n",
    "model = onnx.load(fname)\n",
    "onnx.checker.check_model(model)  # check model is well-formed\n",
    "\n",
    "# create runnable session with exported model\n",
    "ort_session = ort.InferenceSession(fname)\n",
    "net = lambda inp: ort_session.run(None, {'input': inp.data.numpy()})[0]\n",
    "\n",
    "\n",
    "acc_count = 0\n",
    "count = 0\n",
    "for X, Y in testLoader:\n",
    "    # print(net(X))\n",
    "\n",
    "    predictions = net(X).argmax()\n",
    "    acc_count += int(predictions == Y)\n",
    "    count += 1\n",
    "\n",
    "print(f'Torch Model Accuracy (baseline):  {acc_count / count}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "77216b94c1ea9a0b660bed5d746ea0c336c2581033d6cbf52f028a2927c1c1df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
